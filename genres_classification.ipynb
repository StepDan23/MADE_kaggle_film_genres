{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/train.csv'\n",
    "test_path = 'data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path, index_col=0)\n",
    "train_df['target'] = train_df.genres.apply(lambda x: re.findall(\"(?<=')[\\w,-]+(?=')\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(\"<BR>\", \"\", text)\n",
    "    # dot between F.B.I.\n",
    "    text = re.sub(\"\\.\", \"\", text)\n",
    "    # Remove all the special characters\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    # remove all single characters\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    # Substituting multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    # Converting to Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [stemmer.lemmatize(word) for word in tokens]\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['dialogue_prep'] = train_df['dialogue'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df['dialogue_prep']\n",
    "\n",
    "multi_bin = MultiLabelBinarizer()\n",
    "y = multi_bin.fit_transform(train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vect = TfidfVectorizer(max_features=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y(y_pred, n_max=6):\n",
    "    y_new = np.zeros(y_pred.shape)\n",
    "    for ind in range(y_pred.shape[0]):\n",
    "        bound = sum(sorted(y_pred[ind])[::-1][:n_max]) / n_max\n",
    "        y_new[ind] = (y_pred[ind] > bound).astype(int)\n",
    "    return y_new\n",
    "\n",
    "def scorer(est, X_test, y_test):\n",
    "    y_test_proba = est.predict_proba(X_test)\n",
    "    y_pred = convert_y(y_test_proba)\n",
    "    return f1_score(y_pred, y_test, average='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = tf_idf_vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For {'C': 1.5}, score mean= 0.654, std=0.003\n",
      "For {'C': 2.5}, score mean= 0.656, std=0.003\n",
      "For {'C': 3.5}, score mean= 0.656, std=0.004\n"
     ]
    }
   ],
   "source": [
    "params_list = [{'C': 1.5}, {'C': 2.5}, {'C': 3.5}]\n",
    "\n",
    "for params in params_list:\n",
    "    lr = LogisticRegression(**params,)\n",
    "    clf = OneVsRestClassifier(lr)\n",
    "    score = cross_val_score(clf, X_all, y, scoring=scorer, cv=5)\n",
    "    print(f\"For {params}, score mean= {score.mean():.3f}, std={score.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=3.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='warn', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=3.)\n",
    "clf = OneVsRestClassifier(lr)\n",
    "clf.fit(X_all, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_path, index_col=0)\n",
    "test_df['dialogue_prep'] = test_df['dialogue'].apply(lambda x: clean_text(x))\n",
    "X_test_tfidf = tf_idf_vect.transform(test_df['dialogue_prep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba = clf.predict_proba(X_test_tfidf)\n",
    "y_test = convert_y(y_test_proba)\n",
    "test_df['target'] = multi_bin.inverse_transform(y_test)\n",
    "test_df['genres'] = test_df['target'].apply(lambda x: ' '.join(x))\n",
    "test_df[['genres']].to_csv('submit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check zero predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test.sum(axis=1) == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,genres\r\n",
      "0,crime drama\r\n",
      "1,drama thriller\r\n",
      "2,drama\r\n",
      "3,drama romance\r\n",
      "4,action thriller\r\n",
      "5,drama romance thriller\r\n",
      "6,comedy romance\r\n",
      "7,comedy drama romance\r\n",
      "8,drama romance\r\n"
     ]
    }
   ],
   "source": [
    "!head submit.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,genres\r\n",
      "0,crime drama\r\n",
      "1,drama thriller\r\n",
      "2,drama\r\n",
      "3,drama romance\r\n",
      "4,action thriller\r\n",
      "5,drama romance thriller\r\n",
      "6,comedy drama romance\r\n",
      "7,comedy drama romance\r\n",
      "8,drama romance\r\n"
     ]
    }
   ],
   "source": [
    "!head submit.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
